{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ![](https://ga-dash.s3.amazonaws.com/production/assets/logo-9f88ae6c9c3871690e33280fcf557f33.png) Project 4: Web Scraping Job Postings\n",
    "\n",
    "\n",
    "\n",
    "### QUESTION 1: Factors that impact salary\n",
    "\n",
    " 1. Determine the industry factors that are most important in predicting the salary amounts for these data.\n",
    "\n",
    "To predict salary you will be building either a classification or regression model, using features like the location, title, and summary of the job. If framing this as a regression problem, you will be estimating the listed salary amounts. You may instead choose to frame this as a classification problem, in which case you will create labels from these salaries (high vs. low salary, for example) according to thresholds (such as median salary).\n",
    "\n",
    "-------------\n",
    "\n",
    "**Data Overview** \n",
    "\n",
    "Searched keywords: data analyst, data scientist, business analyst, business intelligence, data engineer and analytics. \n",
    "\n",
    "Scraped from mycareersfuture.sg - **914 rows** and **7 columns**, after cleaning\n",
    "feature engineering added **6 columns**. \n",
    "\n",
    "Columns: 'company_name', 'employment_type', 'industry', 'job_description',\n",
    "       'job_title', 'requirements', 'salary_max', 'salary_min', 'seniority',\n",
    "       'salary_avg', 'job_title_clean', 'seniority_clean',\n",
    "       'salary_class'\n",
    "\n",
    "* Target feature is salary class, treshold is deterimined by IQR. \n",
    "       * High Salary is > IQR 75, Low Salary is < IQR 25\n",
    "       * high salary treshold:  9075, low salary treshold:  5500\n",
    "       * Baseline is 'mid' class between high and low salary threshold at ~50% of the entire dataset. \n",
    "\n",
    "Data scraping and cleaning in separate notebook\n",
    "\n",
    "**Problem with job description**: from EDA it seems that many job descriptions were identical to each other. Meaning that different salary levels can have the same job description, which can confuse our models and increase the risk of misclassification.\n",
    "\n",
    "**Hypothesis:**\n",
    "- Prediction will perform better without job description feature\n",
    "\n",
    "**Test**\n",
    "- Test on Job Title, Industry Seniority, Salary class\n",
    "- Test on JD\n",
    "- Test on Requirements\n",
    "- Test on all Features\n",
    "\n",
    "**Models**\n",
    "- Logistic Regression\n",
    "- Stochastic Gradient Classifier\n",
    "- Random Forest Classifier\n",
    "\n",
    "**Evaluation Metric**\n",
    "- F1\n",
    "- Confusion Matrix\n",
    "- Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib;\n",
    "import matplotlib.pyplot as plt;\n",
    "\n",
    "import re;\n",
    "\n",
    "import seaborn as sns;\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'mono';\n",
    "matplotlib.rcParams['font.weight'] = 3;\n",
    "matplotlib.rcParams['font.size'] = 10;\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "sqlite_db = './careers.db'\n",
    "conn = sqlite3.connect(sqlite_db) \n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import metrics \n",
    "from sklearn.naive_bayes import MultinomialNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Classification without JD/Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT industry, job_title_clean, seniority_clean, salary_class\n",
    "FROM alljobs'''\n",
    "\n",
    "all_jobs = pd.read_sql(query, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(model, classes):\n",
    "    vectorizer = model.named_steps['vectorizer']\n",
    "    clf = model.named_steps['clf']\n",
    "\n",
    "    features_names = vectorizer.get_feature_names()\n",
    "    features_names = np.asarray(features_names)\n",
    "\n",
    "    print('Number of features: {} \\n'.format(len(features_names)))\n",
    "\n",
    "    try:\n",
    "        if len(classes) > 2:\n",
    "            for i, label in enumerate(classes):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print('%s: %s' % (label,', '.join(features_names[top10])))\n",
    "        else:\n",
    "            top10 = np.argsort(clf.coef_[0])[-10:] \n",
    "            print('Top 10 features found in %s:' % (classes[1]))\n",
    "            print('%s' % (', '.join(features_names[top10])))\n",
    "    except AttributeError:\n",
    "        top10 = np.argsort(clf.feature_importances_)[-10:]\n",
    "        print('Top 10 features found in %s:' % (classes[1]))\n",
    "        print('%s' % (', '.join(features_names[top10])))\n",
    "    \n",
    "    \n",
    "def get_scores(classes_names):\n",
    "    \n",
    "    y_pred = pipe.predict(X_test) \n",
    "    \n",
    "    confusion = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                             index=['is_{}'.format(classes_names[0]),'is_{}'.format(classes_names[1]), 'is_{}'.format(classes_names[2])],\n",
    "                             columns=['pred_{}'.format(classes_names[0]),'pred_{}'.format(classes_names[1]), 'pred_{}'.format(classes_names[2])]) \n",
    "        \n",
    "    print('Classification Report: \\n')\n",
    "    print(metrics.classification_report(y_test, y_pred))\n",
    "    print('='*60)\n",
    "    print('Accuracy: {}'.format(metrics.accuracy_score(y_test,y_pred)))\n",
    "    print('='*60)\n",
    "    print('Confusion Matrix: \\n')\n",
    "    print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_jobs.salary_class\n",
    "X = all_jobs.industry+' '+all_jobs.job_title_clean+' '+all_jobs.seniority_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((731,), (183,), (731,), (183,))"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Log Regression L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.47      0.35      0.40        46\n",
      "        low       0.71      0.49      0.58        51\n",
      "        mid       0.59      0.78      0.67        86\n",
      "\n",
      "avg / total       0.59      0.59      0.58       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5901639344262295\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         16         3        27\n",
      "is_mid           6        25        20\n",
      "is_low          12         7        67\n"
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer(stop_words='english')\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t1m1 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Logistic Regression L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.50      0.26      0.34        46\n",
      "        low       0.71      0.47      0.56        51\n",
      "        mid       0.56      0.81      0.66        86\n",
      "\n",
      "avg / total       0.59      0.58      0.56       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5792349726775956\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         12         3        31\n",
      "is_mid           3        24        24\n",
      "is_low           9         7        70\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('tfidf',tfidf),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t1m2 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.42      0.46      0.44        46\n",
      "        low       0.61      0.43      0.51        51\n",
      "        mid       0.57      0.64      0.60        86\n",
      "\n",
      "avg / total       0.54      0.54      0.53       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5355191256830601\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         21         6        19\n",
      "is_mid           6        22        23\n",
      "is_low          23         8        55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidfvec = TfidfVectorizer(stop_words='english')\n",
    "SDGC = SGDClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', tfidfvec),\n",
    "                       ('clf',SDGC)])\n",
    "\n",
    "model_t1m3 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       1.00      0.02      0.04        46\n",
      "        low       0.80      0.24      0.36        51\n",
      "        mid       0.50      0.98      0.66        86\n",
      "\n",
      "avg / total       0.71      0.53      0.42       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5300546448087432\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high          1         1        44\n",
      "is_mid           0        12        39\n",
      "is_low           0         2        84\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('tfidf',tfidf),\n",
    "                       ('clf',RF)])\n",
    "\n",
    "model_t1m4 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Result:\n",
    "\n",
    "Best performing model is Logistic Regression with L2 Penalty, with accuracy score, precision and recall of 0.59\n",
    "\n",
    "Generally the fetures in Test 1 are good predictors of mid and low salary, not so much for high salary.\n",
    "\n",
    "Let's try to see if the result with Job Description and Requirements will be better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Classification with JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT industry, job_title_clean, seniority_clean, salary_class, job_description, requirements\n",
    "FROM alljobs'''\n",
    "\n",
    "all_jobs_test2 = pd.read_sql(query, con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = list(set(stopwords.words('english'))) + ['requir', 'descri', 'role', 'senior', 'enterpris', 'minimum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning job description\n",
    "all_jobs_test2['desc_clean'] = all_jobs_test2['job_description'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x).lower())\n",
    "all_jobs_test2['req_clean'] = all_jobs_test2['requirements'].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", x).lower())\n",
    "all_jobs_test2 = all_jobs_test2.drop(['job_description', 'requirements'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((731,), (183,), (731,), (183,))"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = all_jobs_test2.salary_class\n",
    "X = all_jobs_test2.desc_clean\n",
    "X = X.map(lambda x: ' '.join([ps.stem(word)for word in x.split() if word not in stop]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal Log Regression L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.39      0.28      0.33        46\n",
      "        low       0.58      0.51      0.54        51\n",
      "        mid       0.53      0.65      0.59        86\n",
      "\n",
      "avg / total       0.51      0.52      0.51       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5191256830601093\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         13         3        30\n",
      "is_mid           6        26        19\n",
      "is_low          14        16        56\n"
     ]
    }
   ],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t2m1 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 52957 \n",
      "\n",
      "high: look technic, ntuc enterpris, backend, includ, respons ntuc, drive, backend join, deliveri, lead, regulatori\n",
      "mid: valid, inform, track, camri lead, nu camri, camri, campaign, support, develop data, junior\n",
      "low: role responsibilitiesntuc, develop join, chang, member, android develop, look android, camr lead, nu camr, camr, strong\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t2m1, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized Logistic Regression L2 Penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.45      0.22      0.29        46\n",
      "        low       0.83      0.29      0.43        51\n",
      "        mid       0.50      0.84      0.63        86\n",
      "\n",
      "avg / total       0.58      0.53      0.49       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5300546448087432\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         10         1        35\n",
      "is_mid           0        15        36\n",
      "is_low          12         2        72\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfTransformer()\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('tfidf',tfidf),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t2m2 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 52957 \n",
      "\n",
      "high: bank, machin, talent, region, team, learn, drive, machin learn, regulatori, googl\n",
      "mid: brand, sa, media, perform, programm, seo, revenu, support, campaign, report\n",
      "low: demand, work, etl, suppli, engin, technic, infrastructur, design, test, data\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t2m2, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stochastic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.37      0.41      0.39        46\n",
      "        low       0.56      0.37      0.45        51\n",
      "        mid       0.46      0.52      0.49        86\n",
      "\n",
      "avg / total       0.47      0.45      0.45       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.453551912568306\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         19         2        25\n",
      "is_mid           5        19        27\n",
      "is_low          28        13        45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidfvec = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
    "SDGC = SGDClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', tfidfvec),\n",
    "                       ('clf',SDGC)])\n",
    "\n",
    "model_t2m3 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 52957 \n",
      "\n",
      "high: team, look technic, learn, lead, regulatori, deliveri, backend join, tax, drive, googl\n",
      "mid: develop data, valid, promot, cognit, support, facil, seo, sa, report, campaign\n",
      "low: consist, youtub, strong, abus, deep learn, base, work, suppli, chang, test\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t2m3, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.38      0.07      0.11        46\n",
      "        low       1.00      0.02      0.04        51\n",
      "        mid       0.47      0.94      0.62        86\n",
      "\n",
      "avg / total       0.59      0.46      0.33       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.4644808743169399\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high          3         0        43\n",
      "is_mid           0         1        50\n",
      "is_low           5         0        81\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('tfidf',tfidf),\n",
    "                       ('clf',RF)])\n",
    "\n",
    "model_t2m4 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 52957 \n",
      "\n",
      "Top 10 features found in mid:\n",
      "omni channel, everi, dynam seamless, lifecycl, live, platform deliv, channel, background, divers, lap\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t2m4, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** - Although Test 2 didn't perform as well as Test 1, Test 2 is more insightful. For example, two of the models agree that 'regulatory' and 'strategy' are two predictors for high salary, we also found 'learning' which probably refers to 'learning' on a few models. Perhaps we can look into this in Test 4.\n",
    "\n",
    "Similarly Job Description is a good predictor for low and mid salary (more low than mid), not so much for high salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Classification with Requirements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((731,), (183,), (731,), (183,))"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = all_jobs_test2.salary_class\n",
    "X = all_jobs_test2.req_clean\n",
    "X = X.map(lambda x: ' '.join([ps.stem(word)for word in x.split() if word not in stop]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.59      0.43      0.50        46\n",
      "        low       0.59      0.53      0.56        51\n",
      "        mid       0.56      0.67      0.61        86\n",
      "\n",
      "avg / total       0.58      0.57      0.57       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5737704918032787\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         20         2        24\n",
      "is_mid           3        27        21\n",
      "is_low          11        17        58\n"
     ]
    }
   ],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t3m1 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 33666 \n",
      "\n",
      "high: larg, face, disciplin, appli, good understand, success, qualif, consult, min year, min\n",
      "mid: inform technolog, media, manufactur, offic, minimum, diploma, meticul, bachelor comput, follow, minimum bachelor\n",
      "low: excel command, microsoft, demonstr, year, relat, requirementsqualif year, english, complet, phd comput, phd\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t3m1, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.55      0.26      0.35        46\n",
      "        low       0.84      0.31      0.46        51\n",
      "        mid       0.51      0.85      0.64        86\n",
      "\n",
      "avg / total       0.61      0.55      0.52       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5519125683060109\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         12         0        34\n",
      "is_mid           0        16        35\n",
      "is_low          10         3        73\n"
     ]
    }
   ],
   "source": [
    "#### Normalized Logistic Regression L2 Penalty\n",
    "tfidf = TfidfTransformer()\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('tfidf',tfidf),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t3m2 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 33666 \n",
      "\n",
      "high: market, solid, product, requirementsminimum qualif, experi, success, complex, requirementsminimum, consult, qualif\n",
      "mid: pressur, abl, minimum bachelor, inform technolog, employe, media, meticul, benefit, manufactur, diploma\n",
      "low: solut, busi analyst, relat, informatica, bank, complet, busi, phd, experi, data\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t3m2, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.51      0.63      0.56        46\n",
      "        low       0.55      0.43      0.48        51\n",
      "        mid       0.58      0.58      0.58        86\n",
      "\n",
      "avg / total       0.55      0.55      0.55       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5519125683060109\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         29         5        12\n",
      "is_mid           5        22        24\n",
      "is_low          23        13        50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#### Stochastic Model\n",
    "tfidfvec = TfidfVectorizer(stop_words='english')\n",
    "SDGC = SGDClassifier(random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', tfidfvec),\n",
    "                       ('clf',SDGC)])\n",
    "\n",
    "model_t3m3 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 3662 \n",
      "\n",
      "high: fast, fx, requirementsminimum, bw, aaa, focu, disciplin, larg, consult, min\n",
      "mid: manufactur, plu, media, bioinformat, sap, graduat, member, inform, follow, meticul\n",
      "low: analyst, deriv, varieti, output, microsoft, complet, demonstr, relat, sens, phd\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t3m3, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.00      0.00      0.00        46\n",
      "        low       1.00      0.04      0.08        51\n",
      "        mid       0.48      1.00      0.64        86\n",
      "\n",
      "avg / total       0.50      0.48      0.32       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.4808743169398907\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high          0         0        46\n",
      "is_mid           0         2        49\n",
      "is_low           0         0        86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#RF Classifier\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('tfidf',tfidf),\n",
    "                       ('clf',RF)])\n",
    "\n",
    "model_t3m4 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 33955 \n",
      "\n",
      "Top 10 features found in mid:\n",
      "salari, ci tool, requirementsrequir year, background, meticul, offic, diploma, knowledg git, api, requir phd\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t3m4, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Test - All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test on Logistic Regression with Lasso Penalty, best performing model so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stop + ['ntuc', 'profession', 'requirementsrequir', 'responsibilities', 'phd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((731,), (183,), (731,), (183,))"
      ]
     },
     "execution_count": 650,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = all_jobs_test2.salary_class\n",
    "X = all_jobs_test2.desc_clean+ ' '+all_jobs_test2.industry + ' '+ all_jobs_test2.job_title_clean +' '+ all_jobs_test2.seniority_clean +' '+all_jobs_test2.req_clean \n",
    "X = X.map(lambda x: ' '.join([ps.stem(word)for word in x.split() if word not in stop]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.61      0.43      0.51        46\n",
      "        low       0.67      0.57      0.62        51\n",
      "        mid       0.62      0.77      0.68        86\n",
      "\n",
      "avg / total       0.63      0.63      0.62       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.6284153005464481\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         20         2        24\n",
      "is_mid           5        29        17\n",
      "is_low           8        12        66\n"
     ]
    }
   ],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t4m1 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 78075 \n",
      "\n",
      "high: backend join, appli, deliveri, taxat middl, manag good, relat, manag requirementsabout, relat manag, relat year, technolog relat\n",
      "mid: entri, follow, taxat execut, engin bachelor, execut year, bachelor comput, junior, bachelor, data engin, execut\n",
      "low: demonstr, execut requirementsqualif, relat requirementsabout, scientist comput, data scientist, scientist, responsibilitiesntuc part, responsibilitiesntuc, taxat good, technolog year\n"
     ]
    }
   ],
   "source": [
    "get_features(model_t4m1, ['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performing model so far, let's see if we can improve with Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.60      0.33      0.42        46\n",
      "        low       0.58      0.51      0.54        51\n",
      "        mid       0.56      0.73      0.63        86\n",
      "\n",
      "avg / total       0.57      0.57      0.55       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5683060109289617\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         15         4        27\n",
      "is_mid           2        26        23\n",
      "is_low           8        15        63\n"
     ]
    }
   ],
   "source": [
    "#Mehhhh\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer(stop_words=stop, ngram_range=(1,2))),\n",
    "    ('clf', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "model_t4m2 = pipe.fit(X_train, y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Determine the industry factors that are most important in predicting the salary amounts for these data.**\n",
    " \n",
    "From our last model, it seems that high salary requires softskills, such as relationship and management. \n",
    "Whereas Mid to Low salary look more into qualifications such as degree and achievements. The features/ words are messy, given more time I'd like to experiment more with stemming and NLP in general. \n",
    "\n",
    "Job descriptions are similar from one posting to another, thus the variance (and more salient points) are contained in requirements, industry, seniority and job title. Thus models that consider these other features are less likely to misclassify. This probably explained why our last model performed best. \n",
    "\n",
    "If the above assumption is correct, we can prove it by taking 'job description' out of our model and use the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((731,), (183,), (731,), (183,))"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = all_jobs_test2.salary_class\n",
    "X = all_jobs_test2.industry + ' '+ all_jobs_test2.job_title_clean +' '+ all_jobs_test2.seniority_clean +' '+all_jobs_test2.req_clean \n",
    "X = X.map(lambda x: ' '.join([ps.stem(word)for word in x.split() if word not in stop]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.67      0.52      0.59        46\n",
      "        low       0.67      0.63      0.65        51\n",
      "        mid       0.64      0.73      0.68        86\n",
      "\n",
      "avg / total       0.65      0.65      0.65       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.6502732240437158\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         24         1        21\n",
      "is_mid           4        32        15\n",
      "is_low           8        15        63\n"
     ]
    }
   ],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t4m3 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((731,), (183,), (731,), (183,))"
      ]
     },
     "execution_count": 836,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test with Requirements only\n",
    "y = all_jobs_test2.salary_class\n",
    "X = all_jobs_test2.req_clean \n",
    "X = X.map(lambda x: ' '.join([ps.stem(word)for word in x.split() if word not in stop]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.50      0.39      0.44        46\n",
      "        low       0.57      0.53      0.55        51\n",
      "        mid       0.55      0.64      0.59        86\n",
      "\n",
      "avg / total       0.54      0.55      0.54       183\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.546448087431694\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "         pred_high  pred_mid  pred_low\n",
      "is_high         18         2        26\n",
      "is_mid           5        27        19\n",
      "is_low          13        18        55\n"
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_t4m4 = pipe.fit(X_train,y_train)\n",
    "\n",
    "get_scores(['high', 'mid', 'low'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The above proved our hypothesis: results for salary class prediction are better without  JD feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reflection: The longest time I took was to clean the data, as probably expected from any scraping project. Unfortunately the cleaning process was still not thorough enough company names such as NTUC kept popping up as predictor keyword during modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "\n",
    "### QUESTION 2: Factors that distinguish job category\n",
    "\n",
    "Using the job postings you scraped for part 1 (or potentially new job postings from a second round of scraping), identify features in the data related to job postings that can distinguish job titles from each other. There are a variety of interesting ways you can frame the target variable, for example:\n",
    "- What components of a job posting distinguish data scientists from other data jobs?\n",
    "- What features are important for distinguishing junior vs. senior positions?\n",
    "-----------\n",
    "\n",
    "to tackle the questions, I will perform analysis on subsets of the data \n",
    "- Q1 - data scientist, data engineer and data analyst.\n",
    "- Q2 - Junior and Senior only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>seniority_clean</th>\n",
       "      <th>salary_class</th>\n",
       "      <th>desc_clean</th>\n",
       "      <th>req_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Executive</td>\n",
       "      <td>mid</td>\n",
       "      <td>roles   responsibilities design  build  launch...</td>\n",
       "      <td>requirements experience and passion for data e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Banking and Finance</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Professional</td>\n",
       "      <td>mid</td>\n",
       "      <td>roles   responsibilitieswe are looking for a p...</td>\n",
       "      <td>requirementsmandatory skill set  degree in ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>mid</td>\n",
       "      <td>roles   responsibilities integrate all owned m...</td>\n",
       "      <td>requirements   to   years hands on experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineering, Manufacturing</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Junior Executive</td>\n",
       "      <td>low</td>\n",
       "      <td>roles   responsibilitiesresponsibilities      ...</td>\n",
       "      <td>requirementsrequirements    bachelor  master o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Others</td>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Executive</td>\n",
       "      <td>low</td>\n",
       "      <td>roles   responsibilitiesto assist with promoti...</td>\n",
       "      <td>requirements degree in business administration...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     industry   job_title_clean   seniority_clean  \\\n",
       "0      Information Technology     Data Engineer         Executive   \n",
       "1         Banking and Finance  Business Analyst      Professional   \n",
       "2                 Engineering    Data Scientist  Senior Executive   \n",
       "3  Engineering, Manufacturing    Data Scientist  Junior Executive   \n",
       "4                      Others  Business Analyst         Executive   \n",
       "\n",
       "  salary_class                                         desc_clean  \\\n",
       "0          mid  roles   responsibilities design  build  launch...   \n",
       "1          mid  roles   responsibilitieswe are looking for a p...   \n",
       "2          mid  roles   responsibilities integrate all owned m...   \n",
       "3          low  roles   responsibilitiesresponsibilities      ...   \n",
       "4          low  roles   responsibilitiesto assist with promoti...   \n",
       "\n",
       "                                           req_clean  \n",
       "0  requirements experience and passion for data e...  \n",
       "1  requirementsmandatory skill set  degree in ban...  \n",
       "2  requirements   to   years hands on experience ...  \n",
       "3  requirementsrequirements    bachelor  master o...  \n",
       "4  requirements degree in business administration...  "
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs_test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business Analyst       177\n",
       "other                  174\n",
       "Data Engineer          173\n",
       "Data Analyst           121\n",
       "Data Scientist          84\n",
       "Developer               49\n",
       "IT Related              35\n",
       "Marketing Analytics     31\n",
       "Consulting              26\n",
       "HR Related              16\n",
       "Other Data Related      15\n",
       "Product                 13\n",
       "Name: job_title_clean, dtype: int64"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs_test2.job_title_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_jobs = all_jobs_test2[all_jobs_test2.job_title_clean == 'Data Engineer']\n",
    "ds_jobs = all_jobs_test2[all_jobs_test2.job_title_clean == 'Data Scientist']\n",
    "da_jobs = all_jobs_test2[all_jobs_test2.job_title_clean == 'Data Analyst']\n",
    "ds_da_jobs = pd.concat([ds_jobs, da_jobs, de_jobs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Engineer     138\n",
       "Data Analyst      120\n",
       "Data Scientist     80\n",
       "Name: job_title_clean, dtype: int64"
      ]
     },
     "execution_count": 948,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_da_jobs.job_title_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_da_jobs = ds_da_jobs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>seniority_clean</th>\n",
       "      <th>salary_class</th>\n",
       "      <th>desc_clean</th>\n",
       "      <th>req_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Senior Executive</td>\n",
       "      <td>mid</td>\n",
       "      <td>roles   responsibilities integrate all owned m...</td>\n",
       "      <td>requirements   to   years hands on experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Engineering, Manufacturing</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Junior Executive</td>\n",
       "      <td>low</td>\n",
       "      <td>roles   responsibilitiesresponsibilities      ...</td>\n",
       "      <td>requirementsrequirements    bachelor  master o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sciences / Laboratory / R&amp;D</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Professional</td>\n",
       "      <td>mid</td>\n",
       "      <td>roles   responsibilitiesabout the institute fo...</td>\n",
       "      <td>requirements ph  d in the field of computer sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Middle Management</td>\n",
       "      <td>mid</td>\n",
       "      <td>roles   responsibilities    m s  or ph d  in r...</td>\n",
       "      <td>requirementsbasic qualifications   m s  or ph ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Engineering</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Entry Level</td>\n",
       "      <td>low</td>\n",
       "      <td>roles   responsibilitiesdo you have a passion ...</td>\n",
       "      <td>requirementsyou have   at least a bachelor s d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      industry job_title_clean    seniority_clean  \\\n",
       "0                  Engineering  Data Scientist   Senior Executive   \n",
       "1   Engineering, Manufacturing  Data Scientist   Junior Executive   \n",
       "2  Sciences / Laboratory / R&D  Data Scientist       Professional   \n",
       "3       Information Technology  Data Scientist  Middle Management   \n",
       "4                  Engineering  Data Scientist        Entry Level   \n",
       "\n",
       "  salary_class                                         desc_clean  \\\n",
       "0          mid  roles   responsibilities integrate all owned m...   \n",
       "1          low  roles   responsibilitiesresponsibilities      ...   \n",
       "2          mid  roles   responsibilitiesabout the institute fo...   \n",
       "3          mid  roles   responsibilities    m s  or ph d  in r...   \n",
       "4          low  roles   responsibilitiesdo you have a passion ...   \n",
       "\n",
       "                                           req_clean  \n",
       "0  requirements   to   years hands on experience ...  \n",
       "1  requirementsrequirements    bachelor  master o...  \n",
       "2  requirements ph  d in the field of computer sc...  \n",
       "3  requirementsbasic qualifications   m s  or ph ...  \n",
       "4  requirementsyou have   at least a bachelor s d...  "
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_da_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270,), (68,), (270,), (68,))"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just use JD and Requirements\n",
    "y = ds_da_jobs.job_title_clean\n",
    "X = ds_da_jobs.desc_clean +' '+ds_da_jobs.req_clean \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_da_ds = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Data Analyst       0.81      0.89      0.85        28\n",
      " Data Engineer       0.95      0.82      0.88        22\n",
      "Data Scientist       0.78      0.78      0.78        18\n",
      "\n",
      "   avg / total       0.84      0.84      0.84        68\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.8382352941176471\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "                   pred_Data Analyst  pred_Data Scientist  pred_Data Engineer\n",
      "is_Data Analyst                   25                    1                   2\n",
      "is_Data Scientist                  2                   18                   2\n",
      "is_Data Engineer                   4                    0                  14\n"
     ]
    }
   ],
   "source": [
    "get_scores(['Data Analyst', 'Data Scientist', 'Data Engineer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 40334 \n",
      "\n",
      "Data Analyst: analysis, data analytics, reporting, sales, financial, analyst, management, analytics, analytic, business\n",
      "Data Engineer: design, master, technical, engineering, bachelor engineering, engineer, software, bachelor computer, bachelor, requirements bachelor\n",
      "Data Scientist: model, data science, statistics, models, research, scientist, techniques, statistical, requirements engineering, requirements computer\n"
     ]
    }
   ],
   "source": [
    "get_features(model_da_ds, ['Data Analyst', 'Data Engineer', 'Data Scientist'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights\n",
    "The result shows that skills required from a Data Analyst vary from Data Engineer or Data Scientist: \n",
    "* Analytics, Reporting, Financial or Business background is useful for Data Analysts, whereas\n",
    "* Software engineering, technical chops, and at least a bachelor degree in computer science are useful for Data Engineer, whereas\n",
    "* Modeling, statistical knowledge and research are essential for Data Scientist.\n",
    "\n",
    "The scores for this question is significantly more accurate than our first question, I can think of at least two reasons:\n",
    "- Number of samples are smaller thus risk of misclassification is lower\n",
    "- The requirements for each job are specific. \n",
    "\n",
    "I'd also like to test the performance of this subset against our initial hypothesis: performance is better without job description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270,), (68,), (270,), (68,))"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test with job requirements only -- if our hypothesis is true, this should perform better than the above.\n",
    "y = ds_da_jobs.job_title_clean\n",
    "X = ds_da_jobs.req_clean\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_da_ds = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "  Data Analyst       0.81      0.89      0.85        28\n",
      " Data Engineer       0.95      0.86      0.90        22\n",
      "Data Scientist       0.82      0.78      0.80        18\n",
      "\n",
      "   avg / total       0.86      0.85      0.85        68\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.8529411764705882\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "                   pred_Data Analyst  pred_Data Scientist  pred_Data Engineer\n",
      "is_Data Analyst                   25                    1                   2\n",
      "is_Data Scientist                  2                   19                   1\n",
      "is_Data Engineer                   4                    0                  14\n"
     ]
    }
   ],
   "source": [
    "get_scores(['Data Analyst', 'Data Scientist', 'Data Engineer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our hypothesis is true.\n",
    "\n",
    "Further concluded that the salient points that distinguish job functions and salary brackets are contained in Requirements. \n",
    "\n",
    "Unlike Q1 where the performance is worse using Requirements alone, the perfomance here is better, possibly because of the distinct requirements per job functions and also smaller samples.\n",
    "\n",
    "I want to test next if indeed requirements is the most imporant feature to predict the distinct job functions. If this is true, when we test with all other features the performance will be much worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((270,), (68,), (270,), (68,))"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ds_da_jobs.salary_class\n",
    "X = ds_da_jobs.industry + ' '+ ds_da_jobs.job_title_clean +' '+ ds_da_jobs.seniority_clean +' '+ds_da_jobs.req_clean \n",
    "X = X.map(lambda x: ' '.join([ps.stem(word)for word in x.split() if word not in stop]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_da_ds2 = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       high       0.88      0.37      0.52        19\n",
      "        low       0.67      0.50      0.57        20\n",
      "        mid       0.51      0.79      0.62        29\n",
      "\n",
      "avg / total       0.66      0.59      0.58        68\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.5882352941176471\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "                   pred_Data Analyst  pred_Data Scientist  pred_Data Engineer\n",
      "is_Data Analyst                    7                    0                  12\n",
      "is_Data Scientist                  0                   10                  10\n",
      "is_Data Engineer                   1                    5                  23\n"
     ]
    }
   ],
   "source": [
    "get_scores(['Data Analyst', 'Data Scientist', 'Data Engineer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption is true! \n",
    "* High precision, low recall for means our model is quite picky for Data Analyst. \n",
    "* High recall, low precision for means our model classify most as Data Engineer. \n",
    "\n",
    "Let's test if this is also true for Junior vs Senior positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Junior vs Senior Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Professional         335\n",
       "Executive            188\n",
       "other                111\n",
       "Senior Executive     105\n",
       "Middle Management     71\n",
       "Senior Management     52\n",
       "Junior Executive      38\n",
       "Entry Level           14\n",
       "Name: seniority_clean, dtype: int64"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_jobs_test2.seniority_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_jobs_test2['jrvssr'] = ['Senior' if 'senior' in seniority_clean.lower() or 'manage' in seniority_clean.lower() else\n",
    "                            'Junior' if 'junior' in seniority_clean.lower() or 'executive' in seniority_clean.lower() or 'entry' in seniority_clean.lower() else                          \n",
    "                            'Other' for seniority_clean in all_jobs_test2.seniority_clean]\n",
    "jr_jobs = all_jobs_test2[all_jobs_test2.jrvssr == 'Junior']\n",
    "sr_jobs = all_jobs_test2[all_jobs_test2.jrvssr == 'Senior']\n",
    "sr_jr_jobs = pd.concat([jr_jobs, sr_jobs], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Junior    240\n",
       "Senior    228\n",
       "Name: jrvssr, dtype: int64"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Nice balance between Senior and Junior but too many for others. \n",
    "sr_jr_jobs.jrvssr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((374,), (94,), (374,), (94,))"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Just use JD \n",
    "y = sr_jr_jobs.jrvssr\n",
    "X = sr_jr_jobs.desc_clean \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_sr_jr = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Junior       0.69      0.70      0.69        47\n",
      "     Senior       0.70      0.68      0.69        47\n",
      "\n",
      "avg / total       0.69      0.69      0.69        94\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.6914893617021277\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "           is_junior  is_senior\n",
      "is_junior         33         14\n",
      "is_senior         15         32\n"
     ]
    }
   ],
   "source": [
    "model_sr_jr_pred = pipe.predict(X_test) \n",
    "    \n",
    "confusion = pd.DataFrame(confusion_matrix(y_test, model_sr_jr_pred),\n",
    "                         index=['is_junior','is_senior'],\n",
    "                        columns=['is_junior','is_senior'])\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "print(metrics.classification_report(y_test, model_sr_jr_pred))\n",
    "print('='*60)\n",
    "print('Accuracy: {}'.format(metrics.accuracy_score(y_test,model_sr_jr_pred)))\n",
    "print('='*60)\n",
    "print('Confusion Matrix: \\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 42207 \n",
      "\n",
      "Top 10 features found in Senior:\n",
      "scotts, existing, road, learning, business, roles responsibilitieslocation, responsibilitieslocation, closely, architecture, business analyst\n"
     ]
    }
   ],
   "source": [
    "get_features(model_sr_jr, classes=['Junior', 'Senior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((374,), (94,), (374,), (94,))"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## JD alone yield good scores. See if we can improve the performance using requirements alone\n",
    "y = sr_jr_jobs.jrvssr\n",
    "X = sr_jr_jobs.req_clean\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_sr_jr2 = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Junior       0.62      0.72      0.67        47\n",
      "     Senior       0.67      0.55      0.60        47\n",
      "\n",
      "avg / total       0.64      0.64      0.64        94\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.6382978723404256\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "           is_junior  is_senior\n",
      "is_junior         34         13\n",
      "is_senior         21         26\n"
     ]
    }
   ],
   "source": [
    "model_sr_jr_pred = pipe.predict(X_test) \n",
    "    \n",
    "confusion = pd.DataFrame(confusion_matrix(y_test, model_sr_jr_pred),\n",
    "                         index=['is_junior','is_senior'],\n",
    "                        columns=['is_junior','is_senior'])\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "print(metrics.classification_report(y_test, model_sr_jr_pred))\n",
    "print('='*60)\n",
    "print('Accuracy: {}'.format(metrics.accuracy_score(y_test,model_sr_jr_pred)))\n",
    "print('='*60)\n",
    "print('Confusion Matrix: \\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 25644 \n",
      "\n",
      "Top 10 features found in Senior:\n",
      "completed bachelor, requirementsqualifications, able, understanding, business, product, solutions, management, requirementsqualifications years, completed\n"
     ]
    }
   ],
   "source": [
    "get_features(model_sr_jr2, classes=['Junior', 'Senior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((374,), (94,), (374,), (94,))"
      ]
     },
     "execution_count": 949,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nope! For Senior vs Junior, perhaps the distinguishing factors do not lie in Job Requirements. \n",
    "#To test if our hypothesis is still true, let's see if we can improve the \n",
    "#scores using all other features, except job description\n",
    "\n",
    "y = sr_jr_jobs.jrvssr\n",
    "X = sr_jr_jobs.industry + ' '+ sr_jr_jobs.job_title_clean +' '+sr_jr_jobs.req_clean\n",
    "X = X.map(lambda x: ' '.join([ps.stem(word)for word in x.split() if word not in stop]))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normal Log Regression L2 Penalty\n",
    "cvec = CountVectorizer(stop_words=stop, ngram_range=(1,2))\n",
    "logreg = LogisticRegression(penalty= 'l2')\n",
    "\n",
    "pipe = Pipeline(steps=[('vectorizer', cvec),\n",
    "                       ('clf',logreg)])\n",
    "\n",
    "model_sr_jr3 = pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Junior       0.65      0.70      0.67        47\n",
      "     Senior       0.67      0.62      0.64        47\n",
      "\n",
      "avg / total       0.66      0.66      0.66        94\n",
      "\n",
      "============================================================\n",
      "Accuracy: 0.6595744680851063\n",
      "============================================================\n",
      "Confusion Matrix: \n",
      "\n",
      "           is_junior  is_senior\n",
      "is_junior         33         14\n",
      "is_senior         18         29\n"
     ]
    }
   ],
   "source": [
    "model_sr_jr_pred = pipe.predict(X_test) \n",
    "    \n",
    "confusion = pd.DataFrame(confusion_matrix(y_test, model_sr_jr_pred),\n",
    "                         index=['is_junior','is_senior'],\n",
    "                        columns=['is_junior','is_senior'])\n",
    "\n",
    "print('Classification Report: \\n')\n",
    "print(metrics.classification_report(y_test, model_sr_jr_pred))\n",
    "print('='*60)\n",
    "print('Accuracy: {}'.format(metrics.accuracy_score(y_test,model_sr_jr_pred)))\n",
    "print('='*60)\n",
    "print('Confusion Matrix: \\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 23017 \n",
      "\n",
      "Top 10 features found in Senior:\n",
      "requirementsqualif, tool, abl, complet, requirementsqualif year, technolog consult, understand, comput, solut, manag\n"
     ]
    }
   ],
   "source": [
    "get_features(model_sr_jr3, classes=['Junior', 'Senior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope! It performed worse. Thus Job Description contained the most important factor determining seniority. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
